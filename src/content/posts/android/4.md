---
title: termux部署大模型
published: 2025-01-31
description: '讲解如何在termux中部署运行大模型'
image: ''
tags: [人工智能,大模型]
category: '人工智能'
draft: false 
lang: ''
---
# 前言
最近几天我们国产的DeepSeek大模型也是在新年带了，重量级的大模型，对于一个研究ai的人来说这不得把玩一下，那么我们就用点小方法搭建一下吧

# 准备工作
1. ollama软件(主要提供ui部分)

::github{repo="JHubi1/ollama-app"}
2. termux(老演员了)

# 开始
安装ollama有两种方式
- 自己编译
- 官方编译

## 自己编译
自己编译我们需要去拉取代码，然后编译

- 更新termux包

```bash
pkg upgrade
```
- 安装依赖
```bash
pkg install git
```
- 拉取代码
```bash
git clone https://github.com/ollama/ollama.git
```
- 编译工具

```bash
pkg install cmake golang -y
```
进入目录
```bash
cd ollama
```
- 编译
```bash
go generate ./...

go build .
```
退出目录
```bash
cd
```
- 添加到环境
```bash
cp ollama/ollama /data/data/com.termux/files/usr/bin/
```
- 添加模型
```bash
ollama run 你的模型
```
emm，怎么说呢，前几天我还能看到deepseek的模型，我在编写这篇文章时没有找到，笑死

[ollama模型下载页面](https://ollama.org.cn/search)

自己去找模型下载吧，给个大概的数据，骁龙870处理器大概3b模型就是极限了，打点鸡血大概在4b顶天，不知道我的为什么他有一个核心在偷懒，哈哈哈
:::note
小知识:如果你在下载大模型时遇到错误，是因为你没启动ollama的服务导致的我们可以使用
```bash
ollama serve
```
来启动服务，然后在创建一个会话窗口即可使用ollama run 你的模型进行下载
:::
## 官方编译
这个需要我们去部署一个Linux的操作系统，我的话是靠，zerotermux的MOE全能去部署的，想偷懒的我推荐使用[国光大佬](https://www.sqlsec.com/2020/04/termuxlinux.html)的全自动部署脚本
- 安装依赖
```bash
pkg install proot git python -y
```
- 拉取代码(运行代码)
```bash
git clone https://github.com/sqlsec/termux-install-linux
cd termux-install-linux
python termux-linux-install.py
```
- 安装ollama
```bash
curl -fsSL https://ollama.com/install.sh | sh
```
最后和上面一样下载模型运行即可

# 结束

启动后可以在命令行聊天也可以去我上面分享的仓库下载对应的软件进行调用，方便观看